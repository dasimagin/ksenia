# Ksenia (Ksenia stores externally now it all)

### Oleges plans
* RL-LSTM for copy and repeat copy task of binary vector of bits, try method:
   - [ ] Q-Learning with Q-dinamic:
     - [ ] Watkins Q-dynamic from [Learning simple algorithms from examples](https://github.com/wojzaremba/algorithm-learning), paper can be [found](https://arxiv.org/abs/1511.07275)
     - [ ] Penalty on Q-function (from same paper)
   - [ ] Reinforce, maybe reinforce with baseline

* NTM version with RL:
   - [ ] Implement best scheme and compare D-NTM (simple argma in memory) and obvious NTM
   - [ ] Compare other schemes

* Update NTM with additional critic based on different models (future plans):
   - [ ] Understand Recurrent Deterministic Policy Gradient from [Memory-based control with recurrent neural networks](https://paperswithcode.com/paper/memory-based-control-with-recurrent-neural)
   - [ ] Try convolutional critic based on memory
   - [ ] Compare on different datasets

* Read papers:
  - [ ] [Learning Simple algorithms from examples](https://arxiv.org/pdf/1511.07275.pdf)
  - [ ] [Reinforcement learning NTM](https://arxiv.org/pdf/1505.00521.pdf)
  - [ ] [Memory-based control with recurrent neural networks](https://paperswithcode.com/paper/memory-based-control-with-recurrent-neural)
  - [ ] [GLOBAL-TO-LOCAL MEMORY POINTER NETWORKS FOR TASK-ORIENTED DIALOGUE](https://arxiv.org/pdf/1901.04713v1.pdf)
  - [ ] [Learning to Remember More with Less Memorization](https://arxiv.org/pdf/1901.01347.pdf)
